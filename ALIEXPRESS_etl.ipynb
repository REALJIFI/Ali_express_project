{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Librabries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sqlalchemy beautifulSoup4 selenium requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pip install selenium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.aliexpress.com/?src=google&albch=fbrnd&acnt=450-156-4625&isdl=y&aff_short_key=UneMJZVf&albcp=2042458462&albag=71343543599&slnk=&trgt=kwd-14802285088&plac=&crea=619144571406&netw=g&device=c&mtctp=e&memo1=&albbt=Google_7_fbrnd&aff_platform=google&albagn=888888&isSmbActive=false&isSmbAutoCall=false&needSmbHouyi=false&gad_source=1&gclid=Cj0KCQjwtsy1BhD7ARIsAHOi4xbIEXwhBSjq_BOkmoQRXrTfeAqVgXAbrT9UDcXuU4ns9rUJx7dWD1QaAueTEALw_wcB\"\n",
    "r = requests.get(url)\n",
    "\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure Selenium ChromeDriver Options\n",
    "options = Options()\n",
    "Options.headless = True\n",
    "service = Service(executable_path='chromedriver-win64\\chromedriver.exe')\n",
    "\n",
    "# initialize the webdriver\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "#Define the URL\n",
    "url = \"https://www.aliexpress.com/?src=google&albch=fbrnd&acnt=450-156-4625&isdl=y&aff_short_key=UneMJZVf&albcp=2042458462&albag=71343543599&slnk=&trgt=kwd-14802285088&plac=&crea=619144571406&netw=g&device=c&mtctp=e&memo1=&albbt=Google_7_fbrnd&aff_platform=google&albagn=888888&isSmbActive=false&isSmbAutoCall=false&needSmbHouyi=false&gad_source=1&gclid=Cj0KCQjwtsy1BhD7ARIsAHOi4xbIEXwhBSjq_BOkmoQRXrTfeAqVgXAbrT9UDcXuU4ns9rUJx7dWD1QaAueTEALw_wcB\"\n",
    "\n",
    "#Use selenium to open the page\n",
    "\n",
    "#Wait for the dynamic content to load\n",
    "time.sleep(10)\n",
    "\n",
    "#Get the page source and close the browser\n",
    "page_source = driver.page_source\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure Selenium ChromeDriver Options\n",
    "options = Options()\n",
    "Options.headless = True\n",
    "service = Service(executable_path='chromedriver-win64\\chromedriver.exe')\n",
    "\n",
    "# initialize the webdriver\n",
    "driver = webdriver.Chrome(service=service, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize WebDriver (Assuming you have set up WebDriver correctly)\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Lists to store extracted data\n",
    "product_names = []\n",
    "prices = []\n",
    "store_names = []\n",
    "store_links = []\n",
    "shipping_prices = []\n",
    "extra_discounts = []\n",
    "item_sold = []\n",
    "original_prices = []\n",
    "shipping_free_statuses = []\n",
    "\n",
    "# Assuming you know the total number of pages\n",
    "total_pages = 5  # Set total pages as required\n",
    "for page_number in range(1, total_pages + 1):\n",
    "    url = f\"https://www.aliexpress.com/w/wholesale-duvet-cover-.html?page={page_number}&g=y&SearchText=duvet+cover+\"\n",
    "\n",
    "    driver.get(url)\n",
    "    time.sleep(30)\n",
    "\n",
    "    # Parse the loaded page_source\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # Adjust the class selectors based on the current website structure\n",
    "    duvet_king_size = soup.find_all('div', class_='list--gallery--C2f2tvm search-item-card-wrapper-gallery')\n",
    "\n",
    "    for duvet in duvet_king_size:\n",
    "        # product_name\n",
    "        product_name = duvet.find('h3', class_='multi--titleText--nXeOvyr').text\n",
    "\n",
    "        # prices\n",
    "        price = duvet.find('div', class_='multi--price-sale--U-S0jtj').text\n",
    "        # or in a situation where you want to remove the curency icon use \n",
    "        #prices = duvet.find('div', class_='multi--price-sale--U-S0jtj').text.replace('$', '').replace(',', '')\n",
    "\n",
    "        # store_name\n",
    "        store_name = duvet.find('a', class_='cards--storeLink--XkKUQFS').text\n",
    "\n",
    "        # store_link\n",
    "        try:\n",
    "            store_link = duvet.find('a', class_='cards--storeLink--XkKUQFS')['href']\n",
    "        except (TypeError, KeyError):\n",
    "            store_link = ''\n",
    "\n",
    "        # shipping_price\n",
    "        try:\n",
    "            shipping_price = duvet.find('span', class_= 'tag--text--1BSEXVh tag--textStyle--3dc7wLU multi--serviceStyle--1Z6RxQ4').text\n",
    "        except AttributeError:\n",
    "            shipping_price = ''\n",
    "\n",
    "        # extra_discount\n",
    "        try:\n",
    "            extra_discount = duvet.find('span', class_='tag--text--1BSEXVh tag--textStyle--3dc7wLU multi--superStyle--1jUmObG').text\n",
    "        except AttributeError:\n",
    "            extra_discount = ''\n",
    "\n",
    "        # item_sold\n",
    "        try:\n",
    "            item_sold_text = duvet.find('span', class_='multi--trade--Ktbl2jB').text\n",
    "            items_sold_value = item_sold_text.split()[0] if item_sold_text else ''\n",
    "        except AttributeError:\n",
    "            items_sold_value = ''\n",
    "\n",
    "        # Append data to list\n",
    "        product_names.append(product_name)\n",
    "        prices.append(price)\n",
    "        store_names.append(store_name)\n",
    "        store_links.append(store_link)\n",
    "        shipping_prices.append(shipping_price)\n",
    "        extra_discounts.append(extra_discount)\n",
    "        item_sold.append(items_sold_value)\n",
    "\n",
    "        # extracting additional information\n",
    "        former_price = duvet.find_all('div', class_='multi--price-original--1zEQqOK')\n",
    "        original_prices.append(former_price[0].text if former_price else '')\n",
    "\n",
    "        free_shipping = duvet.find_all('span', class_='tag--text--1BSEXVh tag--textStyle--3dc7wLU multi--serviceStyle--1Z6RxQ4')\n",
    "        ship_free = free_shipping[0].text.strip() if free_shipping else ''\n",
    "        shipping_free_statuses.append(ship_free)\n",
    "\n",
    "# Once all the pages' information is extracted, quit the driver\n",
    "driver.quit()\n",
    "\n",
    "# Create DataFrame\n",
    "data = {\n",
    "    'product_name': product_names,\n",
    "    'price': prices,\n",
    "    'store_name': store_names,\n",
    "    'store_link': store_links,\n",
    "    'shipping_price': shipping_prices,\n",
    "    'extra_discount': extra_discounts,\n",
    "    'item_sold': item_sold,\n",
    "    'original_price': original_prices,\n",
    "    'shipping_free_status': shipping_free_statuses\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "# display dataframe\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the raw data\n",
    "df.to_csv('Aliexpressduvetcover.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in a situation where you need to change column name\n",
    "#products.rename({'store_linker' : 'store_link'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Products table\n",
    "product_columns = ['product_name', 'price', 'store_name', 'store_link']\n",
    "#products = df[product_columns].copy()\n",
    "# How to drop duplicates\n",
    "products = df[product_columns].copy().drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# create product id\n",
    "products.index.name = 'product_id'\n",
    "products = products.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['product_name', 'price', 'store_name', 'store_link', 'shipping_price',\n",
       "       'extra_discount', 'item_sold', 'original_price',\n",
       "       'shipping_free_status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discount table\n",
    "discount_columns = ['product_name', 'price', 'original_price', 'extra_discount']\n",
    "discounts = df[discount_columns].copy()\n",
    "\n",
    "# discount id\n",
    "discounts.index.name = 'discount_id'\n",
    "discounts = discounts.reset_index()\n",
    "\n",
    "# removing currency symbols and commas then convert to float\n",
    "discounts['original_price'] = discounts['original_price'].str.replace('ï¿¡', '').str.extract('(/d+)%').astype(float)\n",
    "\n",
    "# extract discount percent value and coin percent value as integer\n",
    "discounts['extra_discount'] = discounts['extra_discount'].str.extract('(/d+)%').astype(float) \n",
    "\n",
    "# filling up missing values\n",
    "discounts.fillna({\n",
    "    'original_price': 0.0,\n",
    "    'extra_discount': 0.0,\n",
    "}, inplace=True)\n",
    "\n",
    "discounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sales Table\n",
    "sales_column = ['product_name','price', 'item_sold',]\n",
    "sales = df[sales_column].copy()\n",
    "\n",
    "# sales id\n",
    "sales.index.name = 'sales_id'\n",
    "sales = sales.reset_index()\n",
    "\n",
    "sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shipping Table\n",
    "shipping_column = ['product_name','shipping_price', 'shipping_free_status']\n",
    "shipping = df[shipping_column].copy()\n",
    "\n",
    "# sales id\n",
    "shipping.index.name = 'shipping_id'\n",
    "shipping = shipping.reset_index()\n",
    "\n",
    "# for replacing string with float\n",
    "# filling up missing values\n",
    "shipping.fillna({\n",
    "    'shipping_price': 0.0,\n",
    "    'shipping_free_status': 0.0,\n",
    "}, inplace=True)\n",
    "\n",
    "shipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving to csv file\n",
    "products.to_csv('products.csv', index=False)\n",
    "discounts.to_csv('discounts.csv', index=False)\n",
    "sales.to_csv('sales.csv', index=False)\n",
    "shipping.to_csv('shipping.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOADING LAYER TO POSTGRES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "db_params = {\n",
    "    'username': os.getenv('DB_USERNAME'),\n",
    "    'password': os.getenv('DB_PASSWORD'),\n",
    "    'host': os.getenv('DB_HOST'),\n",
    "    'port': os.getenv('DB_PORT'),\n",
    "    'database': os.getenv('DB_DATABASE')\n",
    "}\n",
    "\n",
    "# Define db url connection using db parameters\n",
    "db_url = f\"postgresql://{db_params['username']}:{db_params['password']}@{db_params['host']}:{db_params['port']}/{db_params['database']}\"\n",
    "\n",
    "# Create database engine\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "# Connect to the PostgreSQL server\n",
    "with engine.connect() as connection:\n",
    "    # Create tables and load data\n",
    "    products.to_sql('products', connection, index=False, if_exists='replace')\n",
    "    discounts.to_sql('discounts', connection, index=False, if_exists='replace')\n",
    "    sales.to_sql('sales', connection, index=False, if_exists='replace')\n",
    "    shipping.to_sql('shipping', connection, index=False, if_exists='replace')\n",
    "\n",
    "print('Database, table, and data loaded successfully')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
